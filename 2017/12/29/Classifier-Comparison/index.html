<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="Classifier_Comparison"><meta name="keywords" content="julia"><meta name="author" content="Monad Kai,undefined"><meta name="copyright" content="Monad Kai"><title>Classifier_Comparison | Code@浮生记</title><link rel="shortcut icon" href="https://avatars1.githubusercontent.com/u/168751?v=3&s=140"><link rel="stylesheet" href="../../../../css/index.css"><link rel="stylesheet" href="https://cdn.staticfile.org/font-awesome/4.7.0/css/font-awesome.min.css?version=1.5.3"><link rel="dns-prefetch" href="https://cdn.staticfile.org"><link rel="dns-prefetch" href="https://cdn.bootcss.com"><link rel="dns-prefetch" href="https://creativecommons.org"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  localSearch: undefined
} </script></head><body><canvas class="fireworks"></canvas><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar"><div class="toggle-sidebar-info text-center"><span data-toggle="切换文章详情">切换站点概览</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Classifier-Comparison"><span class="toc-number">1.</span> <span class="toc-text">Classifier Comparison</span></a></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="http://oxyywddt8.bkt.clouddn.com/portrait/portrait.jpg"></div><div class="author-info__name text-center">Monad Kai</div><div class="author-info__description text-center">Life is beautiful!</div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="../../../../archives"><span class="pull-left">文章</span><span class="pull-right">86</span></a><a class="author-info-articles__tags article-meta" href="../../../../tags"><span class="pull-left">标签</span><span class="pull-right">21</span></a></div><hr><div class="author-info-links"><div class="author-info-links__title text-center">Links</div><a class="author-info-links__name text-center" href="https://Lstyle1.github.io" target="_blank">Lyn</a><a class="author-info-links__name text-center" href="http://onlookerliu.leanote.com" target="_blank">另外一个关于数学的博客</a><a class="author-info-links__name text-center" href="http://jamesmwh.cn/" target="_blank">James MWH的博客</a><a class="author-info-links__name text-center" href="https://www.liaoxuefeng.com" target="_blank">廖雪峰的网站</a><a class="author-info-links__name text-center" href="http://www.ruanyifeng.com" target="_blank">阮一峰的网络日志</a><a class="author-info-links__name text-center" href="https://www.open-open.com" target="_blank">深度开源</a><a class="author-info-links__name text-center" href="https://www.nowcoder.com" target="_blank">牛客网</a><a class="author-info-links__name text-center" href="https://leetcode.com" target="_blank">LeetCode</a><a class="author-info-links__name text-center" href="http://www.learnyouahaskell.com" target="_blank">Haskell</a><a class="author-info-links__name text-center" href="https://www.kaggle.com/learn/overview" target="_blank">Kaggle</a><a class="author-info-links__name text-center" href="https://developers.google.cn/machine-learning/crash-course/framing/video-lecture" target="_blank">Google的AI课程</a><a class="author-info-links__name text-center" href="https://projecteuler.net/" target="_blank">Project Euler</a><a class="author-info-links__name text-center" href="https://beta.observablehq.com/" target="_blank">Observable Notebook</a><a class="author-info-links__name text-center" href="https://www.juliabox.com" target="_blank">JuliaBox</a><a class="author-info-links__name text-center" href="http://community.schemewiki.org/?scip-solutions" target="_blank">SICP Solutions</a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://user-images.githubusercontent.com/12621342/37325500-23e8f77c-26c9-11e8-8e24-eb4346f1fff5.png)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">Code@浮生记</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus"><a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a><a class="site-page" href="/gallery">Gallery</a></span></div><div id="post-info"><div id="post-title">Classifier_Comparison</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2017-12-29</time><div class="post-meta-wordcount"><span>字数总计: </span><span class="word-count">780</span><span class="post-meta__separator">|</span><span>阅读时长: 5 分钟</span></div></div></div></div><div class="layout" id="content-inner"><article id="post"><div id="post-content"><h1 id="Classifier-Comparison"><a href="#Classifier-Comparison" class="headerlink" title="Classifier Comparison"></a>Classifier Comparison</h1><p>Adapted from <a href="http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html" target="_blank" rel="noopener">http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html</a></p>
<a id="more"></a>
<p>A comparison of a several classifiers in scikit-learn on synthetic datasets. The point of this example is to illustrate the nature of decision boundaries of different classifiers. This should be taken with a grain of salt, as the intuition conveyed by these examples does not necessarily carry over to real datasets.</p>
<p>Particularly in high-dimensional spaces, data can more easily be separated linearly and the simplicity of classifiers such as naive Bayes and linear SVMs might lead to better generalization than is achieved by other classifiers.</p>
<p>The plots show training points in solid colors and testing points semi-transparent. The lower right shows the classification accuracy on the test set.</p>
<figure class="highlight julia"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Python Code source: Gaël Varoquaux</span></span><br><span class="line"><span class="comment">#                     Andreas Müller</span></span><br><span class="line"><span class="comment"># Julia adaptation: Cédric St-Jean</span></span><br><span class="line"><span class="comment"># Modified for documentation by Jaques Grobler</span></span><br><span class="line"><span class="comment"># License: BSD 3 clause</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> ScikitLearn</span><br><span class="line"><span class="keyword">using</span> PyCall</span><br><span class="line"><span class="keyword">using</span> PyPlot</span><br><span class="line"><span class="keyword">using</span> ScikitLearn.CrossValidation: train_test_split</span><br><span class="line"><span class="meta">@pyimport</span> matplotlib.colors as mplc</span><br><span class="line"><span class="meta">@sk_import</span> preprocessing: StandardScaler</span><br><span class="line"><span class="meta">@sk_import</span> datasets: (make_moons, make_circles, make_classification)</span><br><span class="line"><span class="meta">@sk_import</span> neighbors: KNeighborsClassifier</span><br><span class="line"><span class="meta">@sk_import</span> svm: SVC</span><br><span class="line"><span class="meta">@sk_import</span> tree: DecisionTreeClassifier</span><br><span class="line"><span class="meta">@sk_import</span> ensemble: (RandomForestClassifier, AdaBoostClassifier)</span><br><span class="line"><span class="meta">@sk_import</span> naive_bayes: GaussianNB</span><br><span class="line"><span class="meta">@sk_import</span> discriminant_analysis: (LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis)</span><br><span class="line"><span class="keyword">using</span> ScikitLearn.Utils: meshgrid</span><br></pre></td></tr></table></figure>
<figure class="highlight julia"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">h = <span class="number">.02</span>  <span class="comment"># step size in the mesh</span></span><br><span class="line"></span><br><span class="line">names = [<span class="string">"Nearest Neighbors"</span>, <span class="string">"Linear SVM"</span>, <span class="string">"RBF SVM"</span>, <span class="string">"Decision Tree"</span>,</span><br><span class="line">         <span class="string">"Random Forest"</span>, <span class="string">"AdaBoost"</span>, <span class="string">"Naive Bayes"</span>, <span class="string">"Linear Discriminant Analysis"</span>,</span><br><span class="line">         <span class="string">"Quadratic Discriminant Analysis"</span>]</span><br><span class="line">classifiers = [</span><br><span class="line">    KNeighborsClassifier(<span class="number">3</span>),</span><br><span class="line">    SVC(kernel=<span class="string">"linear"</span>, C=<span class="number">0.025</span>),</span><br><span class="line">    SVC(gamma=<span class="number">2</span>, C=<span class="number">1</span>),</span><br><span class="line">    DecisionTreeClassifier(max_depth=<span class="number">5</span>),</span><br><span class="line">    RandomForestClassifier(max_depth=<span class="number">5</span>, n_estimators=<span class="number">10</span>, max_features=<span class="number">1</span>),</span><br><span class="line">    AdaBoostClassifier(),</span><br><span class="line">    GaussianNB(),</span><br><span class="line">    LinearDiscriminantAnalysis(),</span><br><span class="line">    QuadraticDiscriminantAnalysis()]</span><br><span class="line"></span><br><span class="line">X, y = make_classification(n_features=<span class="number">2</span>, n_redundant=<span class="number">0</span>, n_informative=<span class="number">2</span>,</span><br><span class="line">                           random_state=<span class="number">1</span>, n_clusters_per_class=<span class="number">1</span>)</span><br><span class="line">srand(<span class="number">42</span>)</span><br><span class="line">X += <span class="number">2</span> * rand(size(X)...)</span><br><span class="line">linearly_separable = (X, y)</span><br><span class="line"></span><br><span class="line">datasets = [make_moons(noise=<span class="number">0.3</span>, random_state=<span class="number">0</span>),</span><br><span class="line">            make_circles(noise=<span class="number">0.2</span>, factor=<span class="number">0.5</span>, random_state=<span class="number">1</span>),</span><br><span class="line">            linearly_separable</span><br><span class="line">            ];</span><br></pre></td></tr></table></figure>
<figure class="highlight julia"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line">fig = figure(figsize=(<span class="number">27</span>, <span class="number">9</span>))</span><br><span class="line">i = <span class="number">1</span></span><br><span class="line"><span class="comment"># iterate over datasets</span></span><br><span class="line"><span class="keyword">for</span> ds <span class="keyword">in</span> datasets</span><br><span class="line">    <span class="comment"># preprocess dataset, split into training and test part</span></span><br><span class="line">    X, y = ds</span><br><span class="line">    X = fit_transform!(StandardScaler(), X)</span><br><span class="line">    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">.4</span>)</span><br><span class="line"></span><br><span class="line">    x_min, x_max = minimum(X[:, <span class="number">1</span>]) - <span class="number">.5</span>, maximum(X[:, <span class="number">1</span>]) + <span class="number">.5</span></span><br><span class="line">    y_min, y_max = minimum(X[:, <span class="number">2</span>]) - <span class="number">.5</span>, maximum(X[:, <span class="number">2</span>]) + <span class="number">.5</span></span><br><span class="line">    xx, yy = meshgrid(x_min:h:x_max, y_min:h:y_max)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># just plot the dataset first</span></span><br><span class="line">    cm = PyPlot.cm[:RdBu]</span><br><span class="line">    cm_bright = mplc.ListedColormap([<span class="string">"#FF0000"</span>, <span class="string">"#0000FF"</span>])</span><br><span class="line">    ax = subplot(length(datasets), length(classifiers) + <span class="number">1</span>, i)</span><br><span class="line">    <span class="comment"># Plot the training points</span></span><br><span class="line">    ax[:scatter](X_train[:, <span class="number">1</span>], X_train[:, <span class="number">2</span>], c=y_train, cmap=cm_bright)</span><br><span class="line">    <span class="comment"># and testing points</span></span><br><span class="line">    ax[:scatter](X_test[:, <span class="number">1</span>], X_test[:, <span class="number">2</span>], c=y_test, cmap=cm_bright, alpha=<span class="number">0.6</span>)</span><br><span class="line"></span><br><span class="line">    ax[:set_xlim](minimum(xx), maximum(xx))</span><br><span class="line">    ax[:set_ylim](minimum(yy), maximum(yy))</span><br><span class="line">    ax[:set_xticks](())</span><br><span class="line">    ax[:set_yticks](())</span><br><span class="line">    i += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># iterate over classifiers</span></span><br><span class="line">    <span class="keyword">for</span> (name, clf) <span class="keyword">in</span> zip(names, classifiers)</span><br><span class="line">        ax = subplot(length(datasets), length(classifiers) + <span class="number">1</span>, i)</span><br><span class="line">        fit!(clf, X_train, y_train)</span><br><span class="line">        scor = score(clf, X_test, y_test)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Plot the decision boundary. For that, we will assign a color to each</span></span><br><span class="line">        <span class="comment"># point in the mesh [x_min, m_max]x[y_min, y_max].</span></span><br><span class="line">        <span class="keyword">try</span> </span><br><span class="line">            <span class="comment"># Not implemented for some</span></span><br><span class="line">            Z = decision_function(clf, hcat(xx[:], yy[:]))</span><br><span class="line">        <span class="keyword">catch</span></span><br><span class="line">            Z = predict_proba(clf, hcat(xx[:], yy[:]))[:, <span class="number">2</span>]</span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Put the result into a color plot</span></span><br><span class="line">        Z = reshape(Z, size(xx)...)</span><br><span class="line">        ax[:contourf](xx, yy, Z, cmap=cm, alpha=<span class="number">.8</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Plot also the training points</span></span><br><span class="line">        ax[:scatter](X_train[:, <span class="number">1</span>], X_train[:, <span class="number">2</span>], c=y_train, cmap=cm_bright)</span><br><span class="line">        <span class="comment"># and testing points</span></span><br><span class="line">        ax[:scatter](X_test[:, <span class="number">1</span>], X_test[:, <span class="number">2</span>], c=y_test, cmap=cm_bright,</span><br><span class="line">                   alpha=<span class="number">0.6</span>)</span><br><span class="line"></span><br><span class="line">        ax[:set_xlim](minimum(xx), maximum(xx))</span><br><span class="line">        ax[:set_ylim](minimum(yy), maximum(yy))</span><br><span class="line">        ax[:set_xticks](())</span><br><span class="line">        ax[:set_yticks](())</span><br><span class="line">        ax[:set_title](name)</span><br><span class="line"></span><br><span class="line">        ax[:text](maximum(xx) - <span class="number">.3</span>, minimum(yy) + <span class="number">.3</span>, <span class="meta">@sprintf</span>(<span class="string">"%.2f"</span>, scor),</span><br><span class="line">                size=<span class="number">15</span>, horizontalalignment=<span class="string">"right"</span>)</span><br><span class="line">        i += <span class="number">1</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">fig[:subplots_adjust](left=<span class="number">.02</span>, right=<span class="number">.98</span>)</span><br></pre></td></tr></table></figure>
<p><img src="http://oye4atjxc.bkt.clouddn.com/leanote/Classifier_Comparison/output_5_0.png" alt="png"></p>
<pre><code>/Users/kay/.julia/v0.6/Conda/deps/usr/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.
  &quot;This module will be removed in 0.20.&quot;, DeprecationWarning)
</code></pre></div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Monad Kai</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="../../../../onlookerliu.github.io/2017/12/29/Classifier-Comparison/">onlookerliu.github.io/2017/12/29/Classifier-Comparison/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="onlookerliu.github.io" target="_blank">Code@浮生记</a>！</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="../../../../tags/julia/">julia</a></div><div class="post-qr-code"><div class="post-qr-code-item"><img class="post-qr-code__img" src="http://oxyywddt8.bkt.clouddn.com/qrcode/ali-qrcode.jpg"><div class="post-qr-code__desc">支付宝打赏</div></div><div class="post-qr-code-item"><img class="post-qr-code__img" src="http://oxyywddt8.bkt.clouddn.com/qrcode/Wechat.jpeg"><div class="post-qr-code__desc">微信打赏</div></div></div><div class="addthis_inline_share_toolbox pull-right"></div><script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=undefined" async></script><nav id="pagination"><div class="prev-post pull-left"><a href="../Decision-Tree-Regression/"><i class="fa fa-chevron-left">  </i><span>Decision_Tree_Regression</span></a></div><div class="next-post pull-right"><a href="../Cross-Validated-Predictions/"><span>Cross_Validated_Predictions</span><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2017 - 2018 By Monad Kai</div><div class="framework-info"><span>驱动 - </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="busuanzi"><script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file-o"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="../../../../js/third-party/anime.min.js"></script><script src="../../../../js/third-party/jquery.min.js"></script><script src="../../../../js/third-party/jquery.fancybox.min.js"></script><script src="../../../../js/third-party/velocity.min.js"></script><script src="../../../../js/third-party/velocity.ui.min.js"></script><script src="../../../../js/utils.js?version=1.5.3"></script><script src="../../../../js/fancybox.js?version=1.5.3"></script><script src="../../../../js/sidebar.js?version=1.5.3"></script><script src="../../../../js/copy.js?version=1.5.3"></script><script src="../../../../js/fireworks.js?version=1.5.3"></script><script src="../../../../js/transition.js?version=1.5.3"></script><script src="../../../../js/scroll.js?version=1.5.3"></script><script src="../../../../js/head.js?version=1.5.3"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.bootcss.com/mathjax/2.7.2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></body></html>